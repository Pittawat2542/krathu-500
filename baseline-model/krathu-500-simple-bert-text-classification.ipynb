{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Based on https://www.kaggle.com/michalashkenazi/covid19-text-classification-nlp-bert-tensorflow","metadata":{}},{"cell_type":"code","source":"pip install tensorflow-text","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-17T13:33:25.827483Z","iopub.execute_input":"2021-11-17T13:33:25.827813Z","iopub.status.idle":"2021-11-17T13:34:27.602350Z","shell.execute_reply.started":"2021-11-17T13:33:25.827783Z","shell.execute_reply":"2021-11-17T13:34:27.601319Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pip install -q tf-models-official","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-17T13:34:27.604410Z","iopub.execute_input":"2021-11-17T13:34:27.604702Z","iopub.status.idle":"2021-11-17T13:34:57.919649Z","shell.execute_reply.started":"2021-11-17T13:34:27.604676Z","shell.execute_reply":"2021-11-17T13:34:57.918549Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# -- Import Libraries -- \nimport os\nimport numpy as np\nimport random\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\n\nfrom official.nlp import optimization\nfrom nltk.corpus import stopwords\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nfrom tensorflow.keras import layers, losses, preprocessing\n\ntf.get_logger().setLevel('ERROR')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-17T13:35:19.451771Z","iopub.execute_input":"2021-11-17T13:35:19.452154Z","iopub.status.idle":"2021-11-17T13:35:19.458811Z","shell.execute_reply.started":"2021-11-17T13:35:19.452122Z","shell.execute_reply":"2021-11-17T13:35:19.457505Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"SEED = 42","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:35:01.900548Z","iopub.execute_input":"2021-11-17T13:35:01.900807Z","iopub.status.idle":"2021-11-17T13:35:01.910814Z","shell.execute_reply.started":"2021-11-17T13:35:01.900781Z","shell.execute_reply":"2021-11-17T13:35:01.909485Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"os.environ['PYTHONHASHSEED'] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:35:22.225535Z","iopub.execute_input":"2021-11-17T13:35:22.225922Z","iopub.status.idle":"2021-11-17T13:35:22.230848Z","shell.execute_reply.started":"2021-11-17T13:35:22.225867Z","shell.execute_reply":"2021-11-17T13:35:22.229498Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/Pittawat2542/krathu-500/raw/main/labeled/comments-small-labeled.csv","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:35:24.839305Z","iopub.execute_input":"2021-11-17T13:35:24.839625Z","iopub.status.idle":"2021-11-17T13:35:26.075046Z","shell.execute_reply.started":"2021-11-17T13:35:24.839595Z","shell.execute_reply":"2021-11-17T13:35:26.074012Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# -- Global Variables -- \nBATCH_SIZE = 128\nEPOCHS = 16\nLEARNING_RATE = 1e-05 #small gradient steps to prevent forgetting in transfer learning.\n\ntfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\ntfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:35:26.077338Z","iopub.execute_input":"2021-11-17T13:35:26.077721Z","iopub.status.idle":"2021-11-17T13:35:26.083582Z","shell.execute_reply.started":"2021-11-17T13:35:26.077679Z","shell.execute_reply":"2021-11-17T13:35:26.082593Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# -- Load Data -- \ntrain_data = pd.read_csv('comments-small-labeled.csv')\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:35:47.074207Z","iopub.execute_input":"2021-11-17T13:35:47.074553Z","iopub.status.idle":"2021-11-17T13:35:47.164296Z","shell.execute_reply.started":"2021-11-17T13:35:47.074524Z","shell.execute_reply":"2021-11-17T13:35:47.163272Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# -- Split Data to train, validation and test -- \ntrain_X, test_X, train_y, test_y = model_selection.train_test_split(train_data.text.astype(str),\n                                                                  train_data.class_label.astype(str), \n                                                                  test_size=0.15, \n                                                                  random_state = SEED)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:36:29.572159Z","iopub.execute_input":"2021-11-17T13:36:29.572491Z","iopub.status.idle":"2021-11-17T13:36:29.585964Z","shell.execute_reply.started":"2021-11-17T13:36:29.572462Z","shell.execute_reply":"2021-11-17T13:36:29.584982Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# -- convert labels to one hot --\nlabel_encoder = LabelEncoder()\n\nvec = label_encoder.fit_transform(train_y)\ntrain_y = tf.keras.utils.to_categorical(vec)\n\nvec = label_encoder.fit_transform(test_y)\ntest_y = tf.keras.utils.to_categorical(vec)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:36:50.082577Z","iopub.execute_input":"2021-11-17T13:36:50.082927Z","iopub.status.idle":"2021-11-17T13:36:50.090275Z","shell.execute_reply.started":"2021-11-17T13:36:50.082886Z","shell.execute_reply":"2021-11-17T13:36:50.089310Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# -- Creating the Model for Fine Tuning -- \ndef bert_text_classification():\n\n    # - text input -\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n        \n    # - preprocessing layer - \n    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n        \n    # - encoding - \n    encoder_inputs = preprocessing_layer(text_input)\n    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n        \n    # - output -\n    outputs = encoder(encoder_inputs)\n        \n    # - classifier layer -\n    net = outputs['pooled_output']\n    net = tf.keras.layers.Dropout(0.2)(net)\n    net = tf.keras.layers.Dense(3, activation='softmax', name='classifier')(net)\n    \n    model = tf.keras.Model(text_input, net)\n    return model\n        \nmodel = bert_text_classification()     ","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:38:05.127628Z","iopub.execute_input":"2021-11-17T13:38:05.128097Z","iopub.status.idle":"2021-11-17T13:38:11.974734Z","shell.execute_reply.started":"2021-11-17T13:38:05.128058Z","shell.execute_reply":"2021-11-17T13:38:11.973858Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# -- Loss -- \nloss = tf.keras.losses.CategoricalCrossentropy()\n\n# -- Optimizer -- \n# will use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). \ntrain_data_size = len(train_X)\nsteps_per_epoch = int(train_data_size/BATCH_SIZE)\nnum_train_steps = steps_per_epoch * EPOCHS\nnum_warmup_steps = int(0.1*num_train_steps/BATCH_SIZE)\n\noptimizer = optimization.create_optimizer(init_lr=LEARNING_RATE,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')\n\n# -- compile the model --\nmodel.compile(optimizer=optimizer,\n              loss=loss,\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:38:11.976466Z","iopub.execute_input":"2021-11-17T13:38:11.976814Z","iopub.status.idle":"2021-11-17T13:38:11.990308Z","shell.execute_reply.started":"2021-11-17T13:38:11.976778Z","shell.execute_reply":"2021-11-17T13:38:11.989608Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# -- Fine Tuning the Model --\nhistory = model.fit(x=train_X,\n                    y=train_y,\n                    validation_split=0.2,\n                    epochs=EPOCHS,\n                    verbose=1,\n                    batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T13:38:11.991947Z","iopub.execute_input":"2021-11-17T13:38:11.992519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Testing --\nloss, acc = model.evaluate(x=test_X,\n                           y=test_y)\nprint(\"test loss: \", loss, \", test acc: \", 100*acc, \"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}